# ğŸ¥· Motor de Scouting Ninja - CNN Brasil

## DescripciÃ³n

Script automatizado para GitHub Actions que scrapea el Top 100 de jugadores de e-sports desde CNN Brasil, realiza upsert en Supabase con detecciÃ³n automÃ¡tica de regiÃ³n (India), rotaciÃ³n de proxies y manejo de errores silencioso.

## ğŸ¯ CaracterÃ­sticas

- âœ… **Scraping Ninja**: RÃ¡pido y eficiente con Playwright
- âœ… **Upsert automÃ¡tico**: Inserta o actualiza en Supabase
- âœ… **DetecciÃ³n de regiÃ³n**: Tag automÃ¡tico "Region: India" para jugadores indios
- âœ… **Proxy rotation**: Soporte para mÃºltiples servicios de proxy
- âœ… **Anti-detecciÃ³n**: Scripts stealth para evitar bloqueos
- âœ… **Error handling silencioso**: ContinÃºa operando sin fallar
- âœ… **GitHub Actions**: Ejecuta cada 6 horas automÃ¡ticamente

## ğŸ“ Archivos Creados

```
.github/workflows/ninja_scraper.yml  # Workflow de GitHub Actions
cnn_brasil_scraper.py                # Scraper principal
proxy_rotator.py                     # Sistema de rotaciÃ³n de proxies
```

## ğŸš€ Setup GitHub Actions

### 1. Configurar Secrets

Ve a tu repositorio â†’ Settings â†’ Secrets and variables â†’ Actions

AÃ±ade los siguientes secrets:

```
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-anon-key
AIRTABLE_API_KEY=your-airtable-key (opcional)
AIRTABLE_BASE_ID=your-base-id (opcional)
AIRTABLE_TABLE_NAME=GameRadar_Players (opcional)
```

### 2. Configurar Proxies (Opcional)

Para usar proxies, aÃ±ade uno de estos secrets:

**Bright Data:**
```
BRIGHT_DATA_USERNAME=your-username
BRIGHT_DATA_PASSWORD=your-password
BRIGHT_DATA_HOST=brd.superproxy.io
BRIGHT_DATA_PORT=22225
```

**ScraperAPI:**
```
SCRAPERAPI_KEY=your-api-key
```

**Custom Proxies:**
```
PROXY_LIST=host1:port1:user1:pass1,host2:port2:user2:pass2
```

### 3. Activar el Workflow

El workflow se ejecuta:
- â° **AutomÃ¡ticamente cada 6 horas** (cron)
- ğŸ¯ **Manualmente** desde Actions tab
- ğŸ”„ **En cada push** a archivos relacionados

## ğŸ’» Uso Local

### Ejecutar el scraper localmente:

```bash
# 1. Configurar .env con credenciales de Supabase
cp .env.example .env

# 2. Instalar dependencias
pip install -r requirements.txt
playwright install chromium

# 3. Ejecutar scraper
python cnn_brasil_scraper.py
```

### Con proxy rotation:

```python
from cnn_brasil_scraper import CNNBrasilNinjaScraper

# Sin proxies
scraper = CNNBrasilNinjaScraper(use_proxies=False)

# Con proxies
scraper = CNNBrasilNinjaScraper(use_proxies=True)

stats = await scraper.run_ninja_scrape()
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Ajustar selectores CSS

Si la estructura de CNN Brasil cambia, edita los selectores en `cnn_brasil_scraper.py`:

```python
selectors = [
    "article",              # Selector genÃ©rico
    ".card",                # Cards de jugadores
    ".player-card",         # Cards especÃ­ficos
    ".athlete-card",        # Athletes
    "[data-player]",        # Atributo data
]
```

### Modificar frecuencia de ejecuciÃ³n

Edita el cron en `.github/workflows/ninja_scraper.yml`:

```yaml
schedule:
  - cron: '0 */6 * * *'  # Cada 6 horas
  # - cron: '0 */2 * * *'  # Cada 2 horas
  # - cron: '0 0 * * *'    # Diariamente a medianoche
```

## ğŸ“Š Output del Workflow

El workflow genera un resumen en GitHub Actions:

```
### ğŸ¥· Ninja Scraper Results

- **Scraped**: 100 players
- **Errors**: 2
- **Duration**: 45.3s
- **Timestamp**: 2026-02-04 12:00:00 UTC
```

## ğŸ­ Anti-DetecciÃ³n

El scraper incluye mÃºltiples tÃ©cnicas anti-detecciÃ³n:

1. **User-Agent rotation**: Cambia entre diferentes browsers
2. **Headers reales**: Simula navegaciÃ³n humana
3. **WebDriver ocultado**: Elimina la propiedad navigator.webdriver
4. **Chrome runtime mock**: Simula Chrome real
5. **Delays aleatorios**: Evita patrones de bot

## ğŸ” DetecciÃ³n de India

El sistema detecta automÃ¡ticamente jugadores de India:

```python
# Detecta desde:
- Banderas emoji (ğŸ‡®ğŸ‡³)
- Texto "India" o "à¤­à¤¾à¤°à¤¤"
- Servidor/regiÃ³n "IN"
- URL con ".in" o "/in/"

# Si se detecta India:
tags = ["Region: India"]  # Se aÃ±ade automÃ¡ticamente
```

## ğŸ›¡ï¸ Error Handling Silencioso

El scraper usa "ninja mode" - nunca falla:

```python
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    reraise=False  # No reraise = silent failure
)
```

- **3 intentos automÃ¡ticos** con backoff exponencial
- **Errores loggeados** pero no detienen la ejecuciÃ³n
- **Continue-on-error** en GitHub Actions

## ğŸ“ˆ Monitoreo

### Ver logs en GitHub Actions:

1. Ve a tu repo â†’ Actions
2. Click en el workflow "Ninja E-sports Scraper"
3. Click en la ejecuciÃ³n mÃ¡s reciente
4. Expande los pasos para ver logs detallados

### Logs locales:

```bash
# Ver logs del scraper
tail -f ninja_scraper.log
```

## ğŸ”„ Arquitectura de Datos

```
CNN Brasil E-sports
        â†“
   [Scraping con Playwright]
        â†“
   [ValidaciÃ³n con Pydantic]
        â†“
   [DetecciÃ³n de PaÃ­s]
        â†“
   [Upsert en Supabase Bronze]
        â†“ (trigger automÃ¡tico)
   [NormalizaciÃ³n a Silver]
```

## ğŸš¨ Troubleshooting

### El scraper no encuentra jugadores:

1. Verifica que la URL estÃ¡ accesible
2. Revisa los selectores CSS en el cÃ³digo
3. Ejecuta localmente con `headless=False` para debug
4. Revisa los logs en GitHub Actions artifacts

### Problemas con proxies:

1. Verifica que las credenciales son correctas
2. Prueba sin proxies primero (`use_proxies=False`)
3. Revisa que el servicio de proxy estÃ¡ activo

### Errors en Supabase:

1. Verifica que los secrets estÃ¡n configurados
2. Confirma que el schema SQL estÃ¡ aplicado
3. Revisa permisos de Row Level Security

## ğŸ“ Notas de ProducciÃ³n

- **Rate limiting**: El scraper respeta delays de 0.1s entre upserts
- **Timeout**: 15 minutos mÃ¡ximo en GitHub Actions
- **Logs**: Solo errores crÃ­ticos se logguean (modo ninja)
- **Artifacts**: Los logs se guardan 7 dÃ­as si hay fallos

## ğŸ” Seguridad

- âœ… Secrets nunca se exponen en logs
- âœ… Logs de error no incluyen informaciÃ³n sensible
- âœ… User agents rotativos para privacidad
- âœ… Proxies opcionales para anonimato

## ğŸ¯ Roadmap

- [ ] Soporte para mÃ¡s fuentes (ESPN, The Score)
- [ ] ML para mejor extracciÃ³n de datos
- [ ] Dashboard de monitoreo en tiempo real
- [ ] Notificaciones Slack/Discord
- [ ] Cache de resultados para evitar re-scraping

---

**Vibe**: RÃ¡pido, eficiente, tipo ninja ğŸ¥·
